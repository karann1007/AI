{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79092c0e",
   "metadata": {},
   "source": [
    "## Load Necessary Dependenceies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45ef234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import create_react_agent,ToolNode, tools_condition\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b096a2",
   "metadata": {},
   "source": [
    "## Setup Authentication and LLM Client\n",
    "The following code sets up the UAIS environment to authenticate the application and securely connect to the Azure OpenAI services. It retrieves the access token required for authorization and initializes both the LLM and embedding clients using Azure OpenAI authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39038ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import httpx\n",
    "\n",
    "def get_access_token():\n",
    "    auth = \"https://api.uhg.com/oauth2/token\"\n",
    "    scope = \"https://api.uhg.com/.default\"\n",
    "    grant_type = \"client_credentials\"\n",
    "\n",
    "\n",
    "    with httpx.Client() as client:\n",
    "        body = {\n",
    "            \"grant_type\": grant_type,\n",
    "            \"scope\": scope,\n",
    "            \"client_id\": dbutils.secrets.get(scope=\"AIML_Training\", key=\"client_id\"),\n",
    "            \"client_secret\": dbutils.secrets.get(scope=\"AIML_Training\", key=\"client_secret\"),\n",
    "        }\n",
    "        headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "        resp = client.post(auth, headers=headers, data=body, timeout=60)\n",
    "        access_token = resp.json()[\"access_token\"]\n",
    "        return access_token\n",
    "\n",
    "\n",
    "load_dotenv('./Data/UAIS_vars.env')\n",
    "\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "OPENAI_API_VERSION = os.environ[\"OPENAI_API_VERSION\"]\n",
    "EMBEDDINGS_DEPLOYMENT_NAME = os.environ[\"EMBEDDINGS_DEPLOYMENT_NAME\"]\n",
    "MODEL_DEPLOYMENT_NAME = os.environ[\"MODEL_DEPLOYMENT_NAME\"]\n",
    "PROJECT_ID = os.environ['PROJECT_ID']\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=OPENAI_API_VERSION,\n",
    "    azure_deployment = MODEL_DEPLOYMENT_NAME,\n",
    "    temperature=0,\n",
    "    azure_ad_token=get_access_token(),\n",
    "    default_headers={\n",
    "        \"projectId\": PROJECT_ID\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d5fbcb",
   "metadata": {},
   "source": [
    "## Preparing and loading necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4126dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/reference_codes.json', 'r') as f:\n",
    "    reference_codes = json.load(f)\n",
    "\n",
    "with open('./Data/validation_records.json', 'r') as f:\n",
    "    patient_records = json.load(f)\n",
    "\n",
    "with open('./Data/test_records.json', 'r') as f:\n",
    "    test_patient_records = json.load(f)\n",
    "\n",
    "with open('./Data/insurance_policies.json', 'r') as f:\n",
    "    policies = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b684d118",
   "metadata": {},
   "source": [
    "## Defining & Implementing Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6392731b",
   "metadata": {},
   "source": [
    "### Tool 1 - **summarize_patient_record**\n",
    "\n",
    "Tool to calculate the patient age and summarise the patient record. It takes in a parameter as patient record dictionary and returns a LLM generated string output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e34b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def summarize_patient_record(record_str:dict) -> str:\n",
    "    \"\"\"Summarise the patient record using patient record and reference_codes\"\"\"\n",
    "    data = record_str\n",
    "    \n",
    "    dob = datetime.strptime(data['date_of_birth'], \"%Y-%m-%d\")\n",
    "    date_of_service = datetime.strptime(data['date_of_service'], \"%Y-%m-%d\")\n",
    "\n",
    "    # Calculate age\n",
    "    age = date_of_service.year - dob.year - ((date_of_service.month, date_of_service.day) < (dob.month, dob.day))\n",
    "\n",
    "    # Add age to dictionary\n",
    "    data['age'] = age\n",
    "    prompt = f\"\"\"\n",
    "     Create a clearly formatted summary of a patient using the data {data} and mapping the reference codes using {reference_codes}.\n",
    "     Also calculate the age by subtracting date of birth from date of service if the age is not provided to you in the data\n",
    "        Include the following seven labeled sections in the specified order:\n",
    "        • Patient Demographics: Include: name, gender, and age\n",
    "        • Insurance Policy ID\n",
    "        • Diagnoses and Descriptions: Include ICD10 codes and their mapped descriptions.\n",
    "        • Procedures and Descriptions: Include CPT codes and their mapped descriptions.\n",
    "        • Preauthorization Status: Clearly mention if preauthorization was required and whether it was obtained.\n",
    "        • Billed Amount (in USD)\n",
    "        • Date of Service\n",
    "    \"\"\"\n",
    "    result = model.invoke(prompt)\n",
    "    return result.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a55dc4",
   "metadata": {},
   "source": [
    "### Tool 2 - **summarize_policy_guidelines**\n",
    "\n",
    "Tool to summarise the policy guideline. It takes in a parameter as policy ID(string)and returns a LLM generated string output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc36edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def summarize_policy_guidelines(policy_id:str) -> str:\n",
    "    \"\"\"Summarise the policy guidelines using policy_id and reference_codes mentioned in the patient record \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Generate a well-structured and clearly formatted summary for the policy with ID: {policy_id}, using the provided data: {policies} and {reference_codes}.\n",
    "\n",
    "    Your summary should include the following sections in order:\n",
    "\n",
    "    1. **Policy Details**\n",
    "    - Policy ID\n",
    "    - Plan Name\n",
    "\n",
    "    2. **Covered Procedures**\n",
    "    For each procedure listed in the policy, present the following details as separate entries:\n",
    "    - **Procedure Code and Description** (use CPT code mappings)\n",
    "    - **Covered Diagnoses and Descriptions** (use ICD-10 code mappings)\n",
    "    - **Gender Restriction**\n",
    "    - **Age Range**\n",
    "    - **Preauthorization Requirement**\n",
    "    - **Notes on Coverage** (if applicable)\n",
    "\n",
    "    Ensure each procedure is clearly separated and all subpoints are properly labeled for readability.\n",
    "    \"\"\"\n",
    "\n",
    "    result = model.invoke(prompt)\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef9f9ea",
   "metadata": {},
   "source": [
    "### Tool 3 - **get_coverage_status**\n",
    "\n",
    "Tool to summarise the coverage status of the patient. It takes in a parameter of patient summary and policy summary and returns the coverage status as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32affddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_coverage_status(patient_summary:str, policy_summary:str) -> str:\n",
    "    \"\"\"Summarise the coverage status using patient summary and policy summary\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Using the provided patient summary: {patient_summary} and policy summary: {policy_summary}, evaluate whether the claim should be classified as \"APPROVED\" or \"ROUTE FOR REVIEW\" based on the policy guidelines.\n",
    "\n",
    "    A procedure should be marked as \"APPROVED\" **only if all** of the following conditions are met:\n",
    "\n",
    "    1. The patient's diagnosis code(s) match one or more of the policy-covered diagnoses for the claimed procedure.\n",
    "    2. The procedure code is explicitly listed in the policy, and all associated conditions are satisfied.\n",
    "    3. The patient's age falls within the policy-defined age range (inclusive of the lower bound, exclusive of the upper bound).\n",
    "    4. The patient's gender matches the policy’s requirement for the procedure.\n",
    "    5. If the policy requires preauthorization for the procedure, it must have been obtained.\n",
    "\n",
    "    Only procedures and diagnoses explicitly listed in the patient record should be considered during evaluation.\n",
    "\n",
    "    Return a clear decision: either \"APPROVED\" or \"ROUTE FOR REVIEW\".\n",
    "    \"\"\"\n",
    "\n",
    "    result = model.invoke(prompt)\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b61461",
   "metadata": {},
   "source": [
    "**Listing out the tools and binding them with LLM model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d8e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all tools that the LLM should be aware of\n",
    "# These tools were defined earlier using the @tool decorator\n",
    "tools = [summarize_patient_record, summarize_policy_guidelines, get_coverage_status]\n",
    "\n",
    "model_with_tools = model.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d686a0a",
   "metadata": {},
   "source": [
    "## Implementing ReAct Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe8305",
   "metadata": {},
   "source": [
    "**SYSTEM PROMPT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c1345",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_PROMPT_TXT = \"\"\"You are an agent from an insurance company who is an expert in reviewing patient record, reviewing policy guidelines and decide whether the claim needs to approved or need to be routed for human review.\n",
    "\n",
    "Given a patient record, call the below relevant tools and provide the most appropriate response:\n",
    "- summarize_patient_record\n",
    "- summarize_policy_guidelines\n",
    "- get_coverage_status\n",
    "\n",
    "Follow the below steps to help you make more informed decisions:\n",
    "  - Use the patient record and summarise it\n",
    "  - Extract the 'insurance_policy_id' from the patient record and summarise the policy guidelines\n",
    "  - Use the summarised patient record and summarised policy guidelines and determine whether the claim needs to be \"APPROVED\" or \"ROUTE FOR REVIEW\" based on the policy guidelines.\n",
    "\n",
    "If you're unable to find relevant information related to patient or policy or make any certain decisions , just end the process for human to make the decison i.e.ROUTE FOR REVIEW\n",
    "   \n",
    "\n",
    "The final response should contain the following:\n",
    "- Decision - APPROVED or ROUTE FOR REVIEW.\n",
    "- Reason - Summarise why the above decision has been taken\n",
    "\"\"\"\n",
    "AGENT_SYS_PROMPT = SystemMessage(content=AGENT_PROMPT_TXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6984b88b",
   "metadata": {},
   "source": [
    "**Defining the AGENT GRAPH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63043a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Create the node function that handles reasoning and planning using the LLM\n",
    "def tool_calling_llm(state: State) -> State:\n",
    "    return {\"messages\": [model_with_tools.invoke([AGENT_SYS_PROMPT] + state[\"messages\"])]}\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode(tools=tools))\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "# Conditional edge\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    tools_condition, # conditional routing function\n",
    "    # If the latest message (result) from LLM is a tool call request -> tools_condition routes to tools\n",
    "    # If the latest message (result) from LLM is a not a tool call -> tools_condition routes to END\n",
    "    [\"tools\", END]\n",
    ")\n",
    "builder.add_edge(\"tools\", \"tool_calling_llm\") # this is the key feedback loop in the agentic system\n",
    "\n",
    "# Compile Agent Graph\n",
    "healthbuddy_agent = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce99458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "for patient_record in patient_records:\n",
    "    print(patient_record)\n",
    "    input = {\"messages\":[(\"user\",f\"What is the coverage status of {patient_record}\")]}\n",
    "    result = healthbuddy_agent.invoke(input)\n",
    "    responses.append(\n",
    "        {   \n",
    "            \"patient_id\": patient_record[\"patient_id\"],\n",
    "            \"generated_output\": result['messages'][-1].content\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada9671",
   "metadata": {},
   "source": [
    "**Creating csv on validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728398a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"patient_id\", \"generated_output\"]\n",
    "validation_csv_path = \"./agent_validation_record_result.csv\"  # <-- Change this to your desired path\n",
    "\n",
    "# Check if file exists to decide whether to write header\n",
    "write_header = not os.path.exists(validation_csv_path)\n",
    "\n",
    "with open(validation_csv_path, mode='a', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=columns)\n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "    for row in responses:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee6ee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for meaning based comparison \n",
    "def llm_judge(agentReponse: str , actualResponse:str):\n",
    "    prompt = f\"\"\"\n",
    "    You are an evaluator. Compare the agent's response:\n",
    "    {agentReponse}\n",
    "\n",
    "    to the actual response:\n",
    "    {actualResponse}\n",
    "\n",
    "    Score the agent's response from 0 to 10 based on:\n",
    "    - Whether the claim decision matches.\n",
    "    - Whether the reasoning for the decision is the same or sufficiently similar.\n",
    "\n",
    "    Return only the integer score.\n",
    "    \"\"\"\n",
    "\n",
    "    result = model.invoke(prompt)\n",
    "    return int(''.join(filter(str.isdigit, result.content.strip())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f9a90",
   "metadata": {},
   "source": [
    "## AGENT VALIDATION AND AVERAGE SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3131116e",
   "metadata": {},
   "source": [
    "### Meaning based comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3211ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_agent():\n",
    "    df1 = pd.read_csv('./agent_validation_record_result.csv')\n",
    "    df2 = pd.read_csv('./Data/validation_reference_results.csv')\n",
    "    totalscore = 0\n",
    "\n",
    "    # Loop through each row\n",
    "    for i in range(len(patient_records)):\n",
    "        agent_output = df1.iloc[i]['generated_output']\n",
    "        print(agent_output)\n",
    "        print(\"\\n\")\n",
    "        actual_output = df2.iloc[i]['reference_response']\n",
    "        print(actual_output)\n",
    "        print(\"\\n\")\n",
    "        score = llm_judge(agent_output, actual_output)\n",
    "        totalscore += score\n",
    "        print(score)\n",
    "    \n",
    "    print(\"Average Score of the agent is - \",totalscore/len(patient_records))\n",
    "        \n",
    "validate_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7da9fd",
   "metadata": {},
   "source": [
    "## FINAL - TESTING THE AGENT AND SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83580c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_responses = []\n",
    "for patient_record in test_patient_records:\n",
    "    input = {\"messages\":[(\"user\",f\"What is the coverage status of {patient_record}\")]}\n",
    "    result = healthbuddy_agent.invoke(input)\n",
    "    test_responses.append(\n",
    "        {   \n",
    "            \"patient_id\": patient_record[\"patient_id\"],\n",
    "            \"generated_response\": result['messages'][-1].content\n",
    "        })\n",
    "    \n",
    "submission_csv_path = \"./submission.csv\"  # <-- Change this to your desired path\n",
    "submission_columns = [\"patient_id\", \"generated_response\"]\n",
    "\n",
    "# Check if file exists to decide whether to write header\n",
    "write_header = not os.path.exists(submission_csv_path)\n",
    "\n",
    "with open(submission_csv_path, mode='a', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=submission_columns)\n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "    for row in test_responses:\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
